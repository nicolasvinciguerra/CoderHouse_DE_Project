[2023-12-12T01:14:21.681+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_openaq_catchup.load_stations_data scheduled__2023-12-10T00:00:00+00:00 [queued]>
[2023-12-12T01:14:21.876+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_openaq_catchup.load_stations_data scheduled__2023-12-10T00:00:00+00:00 [queued]>
[2023-12-12T01:14:21.982+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 4
[2023-12-12T01:14:22.478+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): load_stations_data> on 2023-12-10 00:00:00+00:00
[2023-12-12T01:14:22.600+0000] {standard_task_runner.py:57} INFO - Started process 319 to run task
[2023-12-12T01:14:22.674+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'dag_openaq_catchup', 'load_stations_data', 'scheduled__2023-12-10T00:00:00+00:00', '--job-id', '326', '--raw', '--subdir', 'DAGS_FOLDER/dag_openaq_catchup.py', '--cfg-path', '/tmp/tmpuowe0q6w']
[2023-12-12T01:14:22.865+0000] {standard_task_runner.py:85} INFO - Job 326: Subtask load_stations_data
[2023-12-12T01:14:23.302+0000] {task_command.py:416} INFO - Running <TaskInstance: dag_openaq_catchup.load_stations_data scheduled__2023-12-10T00:00:00+00:00 [running]> on host 1a187d37aaef
[2023-12-12T01:14:35.603+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_openaq_catchup' AIRFLOW_CTX_TASK_ID='load_stations_data' AIRFLOW_CTX_EXECUTION_DATE='2023-12-10T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-10T00:00:00+00:00'
[2023-12-12T01:14:35.679+0000] {main.py:22} INFO - Archivo de configuracion leido correctamente.
[2023-12-12T01:14:35.682+0000] {utils.py:25} INFO - Obteniendo datos de https://api.openaq.org/v2/locations...
[2023-12-12T01:14:37.749+0000] {utils.py:73} INFO - Conexi√≥n a la base de datos establecida exitosamente.
[2023-12-12T01:14:40.525+0000] {utils.py:90} INFO - Cargando datos en la tabla stg_locations...
[2023-12-12T01:14:47.838+0000] {utils.py:98} INFO - Datos cargados exitosamente en la tabla stg_locations.
[2023-12-12T01:14:47.841+0000] {main.py:51} INFO - Ejecutando query CALL nicolasmvinciguerra_coderhouse.petl_load_dim_location();...
[2023-12-12T01:14:54.205+0000] {logging_mixin.py:154} WARNING - /home/***/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py:736 UserWarning: DB-API extension cursor.connection used
[2023-12-12T01:14:54.337+0000] {taskinstance.py:1937} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/redshift_connector/cursor.py", line 248, in execute
    raise e
  File "/home/airflow/.local/lib/python3.8/site-packages/redshift_connector/cursor.py", line 241, in execute
    self._c.execute(self, operation, args)
  File "/home/airflow/.local/lib/python3.8/site-packages/redshift_connector/core.py", line 1933, in execute
    self.handle_messages(cursor)
  File "/home/airflow/.local/lib/python3.8/site-packages/redshift_connector/core.py", line 2140, in handle_messages
    raise self.error
redshift_connector.error.ProgrammingError: {'S': 'ERROR', 'C': 'XX000', 'M': 'could not open relation with OID 716100', 'W': 'SQL statement "MERGE INTO dim_location USING stg_locations ON dim_location.id = stg_locations.id WHEN MATCHED THEN UPDATE SET id = stg_locations.id, city = stg_locations.city, name = stg_locations.name, country_code = stg_locations.country, sources = stg_locations.sources, ismobile = stg_locations.ismobile, isanalysis = stg_locations.isanalysis, sensortype = stg_locations.sensortype, coordinates_latitude = stg_locations.coordinates_latitude, coordinates_longitude = stg_locations.coordinates_longitude, updated_at = current_timestamp WHEN NOT MATCHED THEN INSERT (id, city, name, country_code, sources, ismobile, isanalysis, sensortype, coordinates_latitude, coordinates_longitude) VALUES (stg_locations.id, stg_locations.city, stg_locations.name, stg_locations.country, stg_locations.sources, stg_locations.ismobile, stg_locations.isanalysis, stg_locations.sensortype, stg_locations.coordinates_latitude, stg_locations.coordinates_longitude)"\nPL/pgSQL function "petl_load_dim_location" line 3 at SQL statement', 'F': '../src/pg/src/backend/access/heap/heapam.c', 'L': '639', 'R': 'local_relation_open'}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/scripts/main.py", line 52, in load_locations
    conn.execute(query)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1370, in execute
    return self._exec_driver_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1674, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/redshift_connector/cursor.py", line 248, in execute
    raise e
  File "/home/airflow/.local/lib/python3.8/site-packages/redshift_connector/cursor.py", line 241, in execute
    self._c.execute(self, operation, args)
  File "/home/airflow/.local/lib/python3.8/site-packages/redshift_connector/core.py", line 1933, in execute
    self.handle_messages(cursor)
  File "/home/airflow/.local/lib/python3.8/site-packages/redshift_connector/core.py", line 2140, in handle_messages
    raise self.error
sqlalchemy.exc.ProgrammingError: (redshift_connector.error.ProgrammingError) {'S': 'ERROR', 'C': 'XX000', 'M': 'could not open relation with OID 716100', 'W': 'SQL statement "MERGE INTO dim_location USING stg_locations ON dim_location.id = stg_locations.id WHEN MATCHED THEN UPDATE SET id = stg_locations.id, city = stg_locations.city, name = stg_locations.name, country_code = stg_locations.country, sources = stg_locations.sources, ismobile = stg_locations.ismobile, isanalysis = stg_locations.isanalysis, sensortype = stg_locations.sensortype, coordinates_latitude = stg_locations.coordinates_latitude, coordinates_longitude = stg_locations.coordinates_longitude, updated_at = current_timestamp WHEN NOT MATCHED THEN INSERT (id, city, name, country_code, sources, ismobile, isanalysis, sensortype, coordinates_latitude, coordinates_longitude) VALUES (stg_locations.id, stg_locations.city, stg_locations.name, stg_locations.country, stg_locations.sources, stg_locations.ismobile, stg_locations.isanalysis, stg_locations.sensortype, stg_locations.coordinates_latitude, stg_locations.coordinates_longitude)"\nPL/pgSQL function "petl_load_dim_location" line 3 at SQL statement', 'F': '../src/pg/src/backend/access/heap/heapam.c', 'L': '639', 'R': 'local_relation_open'}
[SQL: CALL nicolasmvinciguerra_coderhouse.petl_load_dim_location();]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2023-12-12T01:14:54.433+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=dag_openaq_catchup, task_id=load_stations_data, execution_date=20231210T000000, start_date=20231212T011421, end_date=20231212T011454
[2023-12-12T01:14:54.486+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 326 for task load_stations_data ((redshift_connector.error.ProgrammingError) {'S': 'ERROR', 'C': 'XX000', 'M': 'could not open relation with OID 716100', 'W': 'SQL statement "MERGE INTO dim_location USING stg_locations ON dim_location.id = stg_locations.id WHEN MATCHED THEN UPDATE SET id = stg_locations.id, city = stg_locations.city, name = stg_locations.name, country_code = stg_locations.country, sources = stg_locations.sources, ismobile = stg_locations.ismobile, isanalysis = stg_locations.isanalysis, sensortype = stg_locations.sensortype, coordinates_latitude = stg_locations.coordinates_latitude, coordinates_longitude = stg_locations.coordinates_longitude, updated_at = current_timestamp WHEN NOT MATCHED THEN INSERT (id, city, name, country_code, sources, ismobile, isanalysis, sensortype, coordinates_latitude, coordinates_longitude) VALUES (stg_locations.id, stg_locations.city, stg_locations.name, stg_locations.country, stg_locations.sources, stg_locations.ismobile, stg_locations.isanalysis, stg_locations.sensortype, stg_locations.coordinates_latitude, stg_locations.coordinates_longitude)"\nPL/pgSQL function "petl_load_dim_location" line 3 at SQL statement', 'F': '../src/pg/src/backend/access/heap/heapam.c', 'L': '639', 'R': 'local_relation_open'}
[SQL: CALL nicolasmvinciguerra_coderhouse.petl_load_dim_location();]
(Background on this error at: https://sqlalche.me/e/14/f405); 319)
[2023-12-12T01:14:54.615+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2023-12-12T01:14:54.882+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
