[2023-12-12T01:37:49.987+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: update_openaq_dw_hourly_catchup.load_stations_data scheduled__2023-12-06T00:00:00+00:00 [queued]>
[2023-12-12T01:37:50.034+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: update_openaq_dw_hourly_catchup.load_stations_data scheduled__2023-12-06T00:00:00+00:00 [queued]>
[2023-12-12T01:37:50.038+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 4
[2023-12-12T01:37:50.573+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): load_stations_data> on 2023-12-06 00:00:00+00:00
[2023-12-12T01:37:50.648+0000] {standard_task_runner.py:57} INFO - Started process 905 to run task
[2023-12-12T01:37:50.748+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'update_openaq_dw_hourly_catchup', 'load_stations_data', 'scheduled__2023-12-06T00:00:00+00:00', '--job-id', '412', '--raw', '--subdir', 'DAGS_FOLDER/dag_openaq_catchup.py', '--cfg-path', '/tmp/tmpg2j9m8km']
[2023-12-12T01:37:50.916+0000] {standard_task_runner.py:85} INFO - Job 412: Subtask load_stations_data
[2023-12-12T01:37:51.532+0000] {task_command.py:416} INFO - Running <TaskInstance: update_openaq_dw_hourly_catchup.load_stations_data scheduled__2023-12-06T00:00:00+00:00 [running]> on host 2be5b1614f4e
[2023-12-12T01:37:52.407+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='update_openaq_dw_hourly_catchup' AIRFLOW_CTX_TASK_ID='load_stations_data' AIRFLOW_CTX_EXECUTION_DATE='2023-12-06T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-12-06T00:00:00+00:00'
[2023-12-12T01:37:52.462+0000] {main.py:22} INFO - Archivo de configuracion leido correctamente.
[2023-12-12T01:37:52.466+0000] {utils.py:25} INFO - Obteniendo datos de https://api.openaq.org/v2/locations...
[2023-12-12T01:37:54.110+0000] {utils.py:73} INFO - Conexi√≥n a la base de datos establecida exitosamente.
[2023-12-12T01:37:57.267+0000] {utils.py:90} INFO - Cargando datos en la tabla stg_locations...
[2023-12-12T01:38:04.636+0000] {local_task_job_runner.py:115} ERROR - Received SIGTERM. Terminating subprocesses
[2023-12-12T01:38:04.842+0000] {process_utils.py:131} INFO - Sending 15 to group 905. PIDs of all processes in the group: [905]
[2023-12-12T01:38:04.850+0000] {process_utils.py:86} INFO - Sending the signal 15 to group 905
[2023-12-12T01:38:04.856+0000] {taskinstance.py:1632} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-12-12T01:38:05.174+0000] {utils.py:100} ERROR - Error al cargar los datos en la base de datos: Task received SIGTERM signal
[2023-12-12T01:38:05.179+0000] {taskinstance.py:1937} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/opt/airflow/scripts/utils.py", line 91, in load_to_sql
    df.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 2878, in to_sql
    return sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 769, in to_sql
    return pandas_sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1920, in to_sql
    total_inserted = sql_engine.insert_records(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1461, in insert_records
    return table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1023, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 945, in _execute_insert_multi
    result = conn.execute(stmt)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1569, in _execute_clauseelement
    compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 545, in _compile_w_cache
    compiled_sql = self._compiler(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 567, in _compiler
    return dialect.statement_compiler(dialect, self, **kw)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py", line 809, in __init__
    Compiled.__init__(self, dialect, statement, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py", line 464, in __init__
    self.string = self.process(self.statement, **compile_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py", line 499, in process
    return obj._compiler_dispatch(self, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/visitors.py", line 82, in _compiler_dispatch
    return meth(self, **kw)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py", line 4015, in visit_insert
    crud_params = crud._get_crud_params(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/crud.py", line 178, in _get_crud_params
    values = _extend_values_for_multiparams(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/crud.py", line 954, in _extend_values_for_multiparams
    row = {_column_as_key(key): v for key, v in row.items()}
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/crud.py", line 954, in <dictcomp>
    row = {_column_as_key(key): v for key, v in row.items()}
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/coercions.py", line 226, in expect_as_key
    return expect(role, element, **kw)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/coercions.py", line 219, in expect
    return impl._implicit_coercions(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1634, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/scripts/main.py", line 44, in load_locations
    load_to_sql(
  File "/opt/airflow/scripts/utils.py", line 101, in load_to_sql
    raise Exception(f"Error al cargar los datos en la base de datos: {e}")
Exception: Error al cargar los datos en la base de datos: Task received SIGTERM signal
[2023-12-12T01:38:05.386+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=update_openaq_dw_hourly_catchup, task_id=load_stations_data, execution_date=20231206T000000, start_date=20231212T013749, end_date=20231212T013805
[2023-12-12T01:38:05.516+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 412 for task load_stations_data (Error al cargar los datos en la base de datos: Task received SIGTERM signal; 905)
[2023-12-12T01:38:05.776+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=905, status='terminated', exitcode=1, started='01:37:50') (905) terminated with exit code 1
[2023-12-12T01:38:05.791+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 143
[2023-12-12T01:38:05.905+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
